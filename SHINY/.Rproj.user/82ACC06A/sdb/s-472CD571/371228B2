{
    "contents" : "#--------------------------------------------------\n# R Server Code for the Capstone Project Shiny App\n#--------------------------------------------------\n\nsuppressWarnings(library(tm))\nsuppressWarnings(library(stringr))\nsuppressWarnings(library(shiny))\n\n# load One-Gram, Two-Gram, Three-Gram and Four-Gram Data frame files\n# This data is already cleansed with N-Grams frequency in decending order\n# The data was convert to lower case, punctuations removed, numbers removed, \n# white spaces removed, non print characters removed\n\nload(\"fDF1.RData\");\nload(\"fDF2.RData\");\nload(\"fDF3.RData\");\nload(\"fDF4.RData\");\nmesg <- as.character(NULL);\n\n#-------------------------------------------------\n# This function \"Clean up\" the user input string \n# before it is used to predict the next term\n#-------------------------------------------------\nCleanInputString <- function(inStr)\n{\n   # Test sentence\n   #inStr <- \"This is. the; -  .   use's 12\"\n\n   # First remove the non-alphabatical characters\n   inStr <- iconv(inStr, \"latin1\", \"ASCII\", sub=\" \");\n   inStr <- gsub(\"[^[:alpha:][:space:][:punct:]]\", \"\", inStr);\n\n   # Then convert to a Corpus\n   inStrCrps <- VCorpus(VectorSource(inStr))\n\n   # Convert the input sentence to lower case\n   # Remove punctuations, numbers, white spaces\n   # non alphabets characters\n   inStrCrps <- tm_map(inStrCrps, content_transformer(tolower))\n   inStrCrps <- tm_map(inStrCrps, removePunctuation)\n   inStrCrps <- tm_map(inStrCrps, removeNumbers)\n   inStrCrps <- tm_map(inStrCrps, stripWhitespace)\n   inStr <- as.character(inStrCrps[[1]])\n   inStr <- gsub(\"(^[[:space:]]+|[[:space:]]+$)\", \"\", inStr)\n\n   # Return the cleaned resulting senytense\n   # If the resulting string is empty return empty and string.\n   if (nchar(inStr) > 0) {\n       return(inStr); \n   } else {\n       return(\"\");\n   }\n}\n\n#---------------------------------------\n# Description of the Back Off Algorithm\n#---------------------------------------\n# To predict the next term of the user specified sentence\n# 1. first we use a FourGram; the first three words of which are the last three words of the user provided sentence\n#    for which we are trying to predict the next word. The FourGram is already sorted from highest to lowest frequency\n# 2. If no FourGram is found, we back off to ThreeGram (first two words of ThreeGram last two words of the sentence)\n# 3. If no FourGram is found, we back off to TwoGram (first word of TwoGram last word of the sentence)\n# 4. If no TwoGram is found, we back off to OneGram (the most common word with highest frequency)\n#\nPredNextTerm <- function(inStr)\n{\n    assign(\"mesg\", \"in PredNextTerm\", envir = .GlobalEnv)\n  \n    # Clean up the input string and extract only the words with no leading and trailing white spaces\n    inStr <- CleanInputString(inStr);\n\n    # Split the input string across white spaces and then extract the length\n    inStr <- unlist(strsplit(inStr, split=\" \"));\n    inStrLen <- length(inStr);\n\n    nxtTermFound <- FALSE;\n    predNxtTerm <- as.character(NULL);\n    #mesg <<- as.character(NULL);\n    # 1. First test the Four Gram using the four gram data frame\n    if (inStrLen >= 3 & !nxtTermFound)\n    {\n        # Assemble the terms of the input string separated by one white space each\n        inStr1 <- paste(inStr[(inStrLen-2):inStrLen], collapse=\" \");\n\n        # Subset the Four Gram data frame \n        searchStr <- paste(\"^\",inStr1, sep = \"\");\n        fDF4Temp <- fDF4[grep (searchStr, fDF4$terms), ];\n        \n        # Check to see if any matching record returned\n        if ( length(fDF4Temp[, 1]) > 1 )\n        {\n            predNxtTerm <- fDF4Temp[1,1];\n            nxtTermFound <- TRUE;\n            mesg <<- \"Next word is predicted using 4-gram.\"\n        }\n        fDF4Temp <- NULL;\n    }\n\n    # 2. Next test the Three Gram using the three gram data frame\n    if (inStrLen >= 2 & !nxtTermFound)\n    {\n        # Assemble the terms of the input string separated by one white space each\n        inStr1 <- paste(inStr[(inStrLen-1):inStrLen], collapse=\" \");\n\n        # Subset the Three Gram data frame \n        searchStr <- paste(\"^\",inStr1, sep = \"\");\n        fDF3Temp <- fDF3[grep (searchStr, fDF3$terms), ];\n        \n        # Check to see if any matching record returned\n        if ( length(fDF3Temp[, 1]) > 1 )\n        {\n            predNxtTerm <- fDF3Temp[1,1];\n            nxtTermFound <- TRUE;\n            mesg <<- \"Next word is predicted using 3-gram.\"\n        }\n        fDF3Temp <- NULL;\n    }\n\n    # 3. Next test the Two Gram using the three gram data frame\n    if (inStrLen >= 1 & !nxtTermFound)\n    {\n        # Assemble the terms of the input string separated by one white space each\n        inStr1 <- inStr[inStrLen];\n\n        # Subset the Two Gram data frame \n        searchStr <- paste(\"^\",inStr1, sep = \"\");\n        fDF2Temp <- fDF2[grep (searchStr, fDF2$terms), ];\n        \n        # Check to see if any matching record returned\n        if ( length(fDF2Temp[, 1]) > 1 )\n        {\n            predNxtTerm <- fDF2Temp[1,1];\n            nxtTermFound <- TRUE;\n            mesg <<- \"Next word is predicted using 2-gram.\";\n        }\n        fDF2Temp <- NULL;\n    }\n\n    # 4. If no next term found in Four, Three and Two Grams return the most\n    #    frequently used term from the One Gram using the one gram data frame\n    if (!nxtTermFound & inStrLen > 0)\n    {\n        predNxtTerm <- fDF1$terms[1];\n        mesg <- \"No next word found, the most frequent word is selected as next word.\"\n    }\n\n    nextTerm <- word(predNxtTerm, -1);\n       \n    if (inStrLen > 0){\n        dfTemp1 <- data.frame(nextTerm, mesg);\n        return(dfTemp1);\n    } else {\n        nextTerm <- \"\";\n        mesg <-\"\";\n        dfTemp1 <- data.frame(nextTerm, mesg);\n        return(dfTemp1);\n    }\n}\n\nmsg <- \"\"\nshinyServer(function(input, output) {\n        output$prediction <- renderPrint({\n            str2 <- CleanInputString(input$inputString);\n            strDF <- PredNextTerm(str2);\n            input$action;\n            msg <<- as.character(strDF[1,2]);\n            cat(\"\", as.character(strDF[1,1]))\n            cat(\"\\n\\t\");\n            cat(\"\\n\\t\");\n            cat(\"Note: \", as.character(strDF[1,2]));\n            })\n\n        output$text1 <- renderText({\n          paste(\"Input Sentence: \", input$inputString)});\n        \n        output$text2 <- renderText({\n          input$action;\n          #paste(\"Note: \", msg);\n        })\n    }\n)",
    "created" : 1461569667000.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1825351100",
    "id" : "371228B2",
    "lastKnownWriteTime" : 1461569588,
    "path" : "D:/Desktop/New folder/FINAL/SHINY/server.R",
    "project_path" : "server.R",
    "properties" : {
        "notebook_format" : "html_document"
    },
    "source_on_save" : false,
    "type" : "r_source"
}